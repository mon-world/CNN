{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hpi-ArZmZdEH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Conv2D, concatenate, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, Dropout, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Sz2kivPS384"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os, glob, sys\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split # 섞어줌\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq_2yRSjRldt",
        "outputId": "85bd9c7b-7fd8-481b-9ac8-da9e9c77396a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chicken : /content/drive/MyDrive/git/raw-img/chicken/OIP-nCvGaJ7AImbmYsDfVLED5gHaFj.jpeg\n",
            "chicken : /content/drive/MyDrive/git/raw-img/chicken/OIP-R5Mz_a0OvutTBux-Cr0jMwHaFE.jpeg\n",
            "chicken : /content/drive/MyDrive/git/raw-img/chicken/OIP-v1Gm2fW6vU2nmNtZAaCd_QHaFj.jpeg\n",
            "chicken : /content/drive/MyDrive/git/raw-img/chicken/OIP--ysTUSbhCFBjrIdKdu2PpAAAAA.jpeg\n",
            "chicken : /content/drive/MyDrive/git/raw-img/chicken/OIP-Dl-Mf2l17ZXDJMDLLRe5fwHaHc.jpeg\n",
            "chicken : /content/drive/MyDrive/git/raw-img/chicken/OIP-H_sH69SauLfZ7TKWAQfNuQHaFl.jpeg\n",
            "chicken : /content/drive/MyDrive/git/raw-img/chicken/OIP-kt8VrthA0UPAleJ-2QMZvQHaFj.jpeg\n",
            "chicken : /content/drive/MyDrive/git/raw-img/chicken/257.jpeg\n",
            "chicken : /content/drive/MyDrive/git/raw-img/chicken/909.jpeg\n",
            "chicken : /content/drive/MyDrive/git/raw-img/chicken/OIP-55J4CT1nEh3tMehZkQmqLwHaFj.jpeg\n",
            "chicken : /content/drive/MyDrive/git/raw-img/chicken/10.jpeg\n",
            "cat : /content/drive/MyDrive/git/raw-img/cat/1880.jpeg\n",
            "cat : /content/drive/MyDrive/git/raw-img/cat/6.jpeg\n",
            "cat : /content/drive/MyDrive/git/raw-img/cat/ea34b20c2ef6013ed1584d05fb1d4e9fe777ead218ac104497f5c978a7e8b7bc_640.jpg\n",
            "cat : /content/drive/MyDrive/git/raw-img/cat/eb30b8092df4073ed1584d05fb1d4e9fe777ead218ac104497f5c978a7ebb0bb_640.jpg\n",
            "cat 991 번째에서 에러 /content/drive/MyDrive/git/raw-img/cat/1.xml\n",
            "cat 992 번째에서 에러 /content/drive/MyDrive/git/raw-img/cat/2.xml\n",
            "cat 993 번째에서 에러 /content/drive/MyDrive/git/raw-img/cat/3.xml\n",
            "cat 994 번째에서 에러 /content/drive/MyDrive/git/raw-img/cat/5.xml\n",
            "cat 995 번째에서 에러 /content/drive/MyDrive/git/raw-img/cat/7.xml\n",
            "cat 996 번째에서 에러 /content/drive/MyDrive/git/raw-img/cat/9.xml\n",
            "cat 997 번째에서 에러 /content/drive/MyDrive/git/raw-img/cat/10.xml\n",
            "cat 998 번째에서 에러 /content/drive/MyDrive/git/raw-img/cat/11.xml\n",
            "cat 999 번째에서 에러 /content/drive/MyDrive/git/raw-img/cat/12.xml\n",
            "cat : /content/drive/MyDrive/git/raw-img/cat/1277.jpeg\n",
            "cat : /content/drive/MyDrive/git/raw-img/cat/1666.jpeg\n",
            "dog : /content/drive/MyDrive/git/raw-img/dog/OIP-kUoCYpDaPmEK7jnELjVOHwHaEK.jpeg\n",
            "dog : /content/drive/MyDrive/git/raw-img/dog/OIP-MQMuV4priroXt0WoOOK9VAHaE8.jpeg\n",
            "dog : /content/drive/MyDrive/git/raw-img/dog/OIP-OoQ7xRdLq3oXGKWVxMKJzwHaFq.jpeg\n",
            "dog : /content/drive/MyDrive/git/raw-img/dog/OIP-qJrOayNeNYbu0P_ZN_ge2gHaHj.jpeg\n",
            "dog : /content/drive/MyDrive/git/raw-img/dog/OIP-F9qPQthhZA18jvHPgv6jmQHaEj.jpeg\n",
            "dog : /content/drive/MyDrive/git/raw-img/dog/OIP-HdziKALnyXPNHiHJUqYjPgHaE7.jpeg\n",
            "dog : /content/drive/MyDrive/git/raw-img/dog/OIP-Jgn2Wm0qtxydL42Q6hXQ2wHaJi.jpeg\n",
            "dog : /content/drive/MyDrive/git/raw-img/dog/OIP-6furhdTd-uDJOqgJSnaBmQHaEL.jpeg\n",
            "dog : /content/drive/MyDrive/git/raw-img/dog/OIP-9XCHs9GEq7Lk2ZDGSdG16gHaF2.jpeg\n",
            "dog : /content/drive/MyDrive/git/raw-img/dog/OIP-BuCkWMFG-BugrK6l6Nmf-wHaJ4.jpeg\n",
            "dog : /content/drive/MyDrive/git/raw-img/dog/OIF-e2bexWrojgtQnAPPcUfOWQ.jpeg\n",
            "dog : /content/drive/MyDrive/git/raw-img/dog/OIP-3_l_T4_hU5o21odZdEHlfAHaFc.jpeg\n",
            "cow : /content/drive/MyDrive/git/raw-img/cow/OIP-iOCO0gieO0oskj_NLw85AAHaFj.jpeg\n",
            "cow : /content/drive/MyDrive/git/raw-img/cow/OIP-nPkR00RdkcFbcap399mAYgHaFi.jpeg\n",
            "cow : /content/drive/MyDrive/git/raw-img/cow/OIP-SyGdC3jWV9OmhciBp_wzMwHaFa.jpeg\n",
            "cow : /content/drive/MyDrive/git/raw-img/cow/OIP-yCWEU_ZFts2hKPG70J20kAHaFj.jpeg\n",
            "cow : /content/drive/MyDrive/git/raw-img/cow/OIP-5rpbTamg1JP9gZjIpi27egHaEx.jpeg\n",
            "cow : /content/drive/MyDrive/git/raw-img/cow/OIP-cuVfwlo5zJbCC1LzAv2QgwHaEL.jpeg\n",
            "cow : /content/drive/MyDrive/git/raw-img/cow/OIP-hfnSs0ZKbXYFecM0HkTTQAHaGS.jpeg\n"
          ]
        }
      ],
      "source": [
        "img_dir = '/content/drive/MyDrive/git/raw-img'\n",
        "categories = ['chicken','cat','dog','cow']\n",
        "np_classes = len(categories)\n",
        "\n",
        "image_w = 224\n",
        "image_h = 224\n",
        "\n",
        "pixel = image_h * image_w * 3\n",
        "\n",
        "X=[]\n",
        "y=[]\n",
        "\n",
        "# X와 y를 정하는 반복문\n",
        "for idx, messy_desk in enumerate(categories) : \n",
        "\n",
        "    img_dir_detail = img_dir + \"/\" + messy_desk\n",
        "    files = glob.glob(img_dir_detail + \"/*\") \n",
        "\n",
        "    for i, f in enumerate(files) :\n",
        "        try :\n",
        "            img = Image.open(f)\n",
        "            img = img.convert(\"RGB\")\n",
        "            img = img.resize((image_w, image_h))\n",
        "            data = np.asarray(img)\n",
        "            # Y는 0 아니면 1 이므로 idx 값으로 넣는다.\n",
        "            X.append(data)\n",
        "            y.append(idx)\n",
        "            if i % 300 == 0 :\n",
        "                print(messy_desk, \":\", f)\n",
        "      \n",
        "        except :\n",
        "            print(messy_desk, str(i) + \" 번째에서 에러\", f)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# train set 0.9, test set 0.1\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT8-7t20Z5sP",
        "outputId": "0d315ea1-eed1-4acb-ef1e-f6b1f6387607"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9095, 224, 224, 3)\n",
            "9095\n",
            "[2799 1508 3106 1682]\n",
            "[299 160 368 184]\n"
          ]
        }
      ],
      "source": [
        "# 고양이, 개, 소, 닭 구별하는 전처리 파일.\n",
        "# 정규화\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "print(X_train.shape)        # (9095, 100, 100, 3)\n",
        "print(X_train.shape[0])     # 9095\n",
        "print(np.bincount(y_train)) # [2788 1499 3122 1686]\n",
        "print(np.bincount(y_test))  # [310 169 352 180]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef2qw6HVbgC6"
      },
      "outputs": [],
      "source": [
        "# resNet 모델 작성\n",
        "def model_res():\n",
        "\n",
        "    # F(X) = F(X) + X\n",
        "    def indentity_block(X, f, filters):\n",
        "        \n",
        "        # 필터 갯수\n",
        "        F1, F2, F3 = filters\n",
        "\n",
        "        # X 저장 \n",
        "        X_shortcut = X\n",
        "\n",
        "        # F(X)\n",
        "        # 첫번째 conv layer\n",
        "        X = Conv2D(F1, (1, 1), strides = (1, 1), padding = 'valid')(X)\n",
        "        X = layers.BatchNormalization(axis = 3)(X)\n",
        "        X = layers.Activation('relu')(X)\n",
        "\n",
        "        # 두번쨰 conv layer\n",
        "        X = Conv2D(F2, (f, f), strides = (1, 1), padding = 'same')(X)\n",
        "        X = layers.BatchNormalization(axis = 3)(X)\n",
        "        X = layers.Activation('relu')(X)\n",
        "\n",
        "        # 세번째 conv layer\n",
        "        X = Conv2D(F3, (1, 1), strides = (1, 1), padding = 'valid')(X)\n",
        "        X = layers.BatchNormalization(axis = 3)(X)\n",
        "\n",
        "        # F(X) + X\n",
        "        # 첫번째와 세번째는 1x1이고 두번째는 padding이 same 이므로 shape는 동일하다.\n",
        "        X = layers.Add()([X, X_shortcut])\n",
        "        X = layers.Activation('relu')(X)\n",
        "\n",
        "        return X\n",
        "\n",
        "    # F(X) = F(X) + G(X) : 숏컷 적용 레이어\n",
        "    def Conv_Block(X, f, filters, s = 2):\n",
        "        \n",
        "        # 필터 갯수\n",
        "        F1, F2, F3 = filters\n",
        "\n",
        "        # X 저장\n",
        "        X_shortcut = X\n",
        "\n",
        "        # F(X)\n",
        "        # 첫번째 conv layer\n",
        "        X = Conv2D(F1, (1, 1), strides = (s, s), padding = 'valid')(X)\n",
        "        X = layers.BatchNormalization(axis = 3)(X)\n",
        "        X = layers.Activation('relu')(X)\n",
        "\n",
        "        # 두번쨰 conv layer\n",
        "        X = Conv2D(F2, (f, f), strides = (1, 1), padding = 'same')(X)\n",
        "        X = layers.BatchNormalization(axis = 3)(X)\n",
        "        X = layers.Activation('relu')(X)\n",
        "\n",
        "        # 세번째 conv layer\n",
        "        X = Conv2D(F3, (1, 1), strides = (1, 1), padding = 'valid')(X)\n",
        "        X = layers.BatchNormalization(axis = 3)(X)\n",
        "        \n",
        "        # G(X) \n",
        "        # shortcut layer\n",
        "        X_shortcut = Conv2D(F3, (1, 1), strides = (s, s), padding= 'valid')(X_shortcut)   \n",
        "        X_shortcut = layers.BatchNormalization(axis = 3)(X_shortcut)\n",
        "\n",
        "        # F(X) + G(X)\n",
        "        X = layers.Add()([X, X_shortcut])\n",
        "        X = layers.Activation('relu')(X)\n",
        "\n",
        "        return X \n",
        "\n",
        "    # resNet50 은 다음과 같은 구조를 갖는다.\n",
        "    # 0. (3,3) 제로 패딩\n",
        "    # 1. Conv2D 사용. s = 2인 7x7 크기 필터 64개, 배치 정규화, relu 사용, MaxPooling 사용\n",
        "    # 2. Conv_Block 사용. s = 1인 3x3 크기 필터 64x64x256개 사용\n",
        "    #    indentity_block 2번 사용. 3x3 크기 필터 64x64x256개 사용\n",
        "    # 3. Conv_Block 사용. s = 2인 3x3 크기 필터 128x128x512개 사용\n",
        "    #    indentity_block 2번 사용. 3x3 크기 필터 128x128x512개 사용\n",
        "    # 4. Conv_Block 사용. s = 2인 3x3 크기 필터 256x256x1024개 사용\n",
        "    #    indentity_block 2번 사용. 3x3 크기 필터 256x256x1024개 사용\n",
        "    # 5. Conv_Block 사용. s = 2인 3x3 크기 필터 512x512x2048개 사용\n",
        "    #    indentity_block 2번 사용. 3x3 크기 필터 256x256x1024개 사용\n",
        "    # 6. AveragePooling 사용. 2x2\n",
        "    # 7. Dense layer\n",
        "\n",
        "    input_img = Input((224, 224, 3))\n",
        "\n",
        "    # 0. (3,3) 제로 패딩\n",
        "    # 1. Conv2D 사용. s = 2인 7x7 크기 필터 64개, 배치 정규화, relu 사용, MaxPooling 사용\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), padding = \"same\")(input_img)\n",
        "    X = layers.BatchNormalization(axis = 3)(X)\n",
        "    X = layers.Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides = (2, 2))(X)\n",
        "\n",
        "    # 2. Conv_Block 사용. s = 1인 3x3 크기 필터 64x64x256개 사용\n",
        "    #    indentity_block 2번 사용. 3x3 크기 필터 64x64x256개 사용\n",
        "    X = Conv_Block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
        "    X = indentity_block(X, 3, [64, 64, 256])\n",
        "    X = indentity_block(X, 3, [64, 64, 256])\n",
        "\n",
        "    # 3. Conv_Block 사용. s = 2인 3x3 크기 필터 128x128x512개 사용\n",
        "    #    indentity_block 2번 사용. 3x3 크기 필터 128x128x512개 사용\n",
        "    X = Conv_Block(X, 3, [128, 128, 512])\n",
        "    X = indentity_block(X, 3, [128, 128, 512])\n",
        "    X = indentity_block(X, 3, [128, 128, 512])\n",
        "\n",
        "    # 4. Conv_Block 사용. s = 2인 3x3 크기 필터 256x256x1024개 사용\n",
        "    #    indentity_block 5번 사용. 3x3 크기 필터 256x256x1024개 사용\n",
        "    X = Conv_Block(X, 3, [256, 256, 1024])\n",
        "    X = indentity_block(X, 3, [256, 256, 1024])\n",
        "    X = indentity_block(X, 3, [256, 256, 1024])\n",
        "    X = indentity_block(X, 3, [256, 256, 1024])\n",
        "    X = indentity_block(X, 3, [256, 256, 1024])\n",
        "    X = indentity_block(X, 3, [256, 256, 1024])\n",
        "\n",
        "    # 5. Conv_Block 사용. s = 2인 3x3 크기 필터 512x512x2048개 사용\n",
        "    #    indentity_block 2번 사용. 3x3 크기 필터 256x256x1024개 사용\n",
        "    X = Conv_Block(X, 3, [512, 512, 2048])\n",
        "    X = indentity_block(X, 3, [512, 512, 2048])\n",
        "    X = indentity_block(X, 3, [512, 512, 2048])\n",
        "\n",
        "    # 6. AveragePooling 사용. 2x2\n",
        "    X = AveragePooling2D(2, 2)(X)\n",
        "\n",
        "    # 7. Dense layer\n",
        "    X = Flatten()(X)\n",
        "    out = Dense(4, activation=\"softmax\")(X)\n",
        "\n",
        "    model = Model(inputs = input_img, outputs = out)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-XQuuv_ad4R",
        "outputId": "140465be-835a-42ed-c376-6e526ec0c05a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 112, 112, 64  9472        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 112, 112, 64  256        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 112, 112, 64  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 55, 55, 64)   0           ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 55, 55, 64)   4160        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 55, 55, 64)  256         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 55, 55, 64)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 55, 55, 64)   36928       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 55, 55, 64)  256         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 55, 55, 64)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 55, 55, 256)  16640       ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 55, 55, 256)  16640       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 55, 55, 256)  1024       ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 55, 55, 256)  1024       ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 55, 55, 256)  0           ['batch_normalization_3[0][0]',  \n",
            "                                                                  'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 55, 55, 256)  0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 55, 55, 64)   16448       ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 55, 55, 64)  256         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 55, 55, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 55, 55, 64)   36928       ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 55, 55, 64)  256         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 55, 55, 64)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 55, 55, 256)  16640       ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 55, 55, 256)  1024       ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 55, 55, 256)  0           ['batch_normalization_7[0][0]',  \n",
            "                                                                  'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 55, 55, 256)  0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 55, 55, 64)   16448       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 55, 55, 64)  256         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 55, 55, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 55, 55, 64)   36928       ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 55, 55, 64)  256         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 55, 55, 64)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 55, 55, 256)  16640       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 55, 55, 256)  1024       ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 55, 55, 256)  0           ['batch_normalization_10[0][0]', \n",
            "                                                                  'activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 55, 55, 256)  0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 28, 28, 128)  32896       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 28, 28, 128)  512        ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 28, 28, 128)  512        ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 28, 28, 512)  66048       ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 28, 28, 512)  131584      ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 28, 28, 512)  0           ['batch_normalization_13[0][0]', \n",
            "                                                                  'batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 28, 28, 512)  0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 28, 28, 128)  65664       ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 28, 28, 128)  512        ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 28, 28, 128)  512        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 28, 28, 512)  66048       ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 28, 28, 512)  0           ['batch_normalization_17[0][0]', \n",
            "                                                                  'activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 28, 28, 512)  0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 28, 28, 128)  65664       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 28, 28, 128)  512        ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 28, 28, 128)  512        ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 28, 28, 512)  66048       ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 28, 28, 512)  0           ['batch_normalization_20[0][0]', \n",
            "                                                                  'activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 28, 28, 512)  0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 14, 14, 256)  131328      ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_20[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 14, 14, 1024  525312      ['activation_18[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_23[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_24[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 14, 14, 1024  0           ['batch_normalization_23[0][0]', \n",
            "                                )                                 'batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 14, 14, 1024  0           ['add_6[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_23[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_27[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 14, 14, 1024  0           ['batch_normalization_27[0][0]', \n",
            "                                )                                 'activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 14, 14, 1024  0           ['add_7[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_26[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_30[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 14, 14, 1024  0           ['batch_normalization_30[0][0]', \n",
            "                                )                                 'activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 14, 14, 1024  0           ['add_8[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_29[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_33[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 14, 14, 1024  0           ['batch_normalization_33[0][0]', \n",
            "                                )                                 'activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 14, 14, 1024  0           ['add_9[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_32[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_36[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_36[0][0]', \n",
            "                                )                                 'activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 14, 14, 1024  0           ['add_10[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 14, 14, 256)  262400      ['activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 14, 14, 1024  263168      ['activation_35[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_39[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_39[0][0]', \n",
            "                                )                                 'activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 14, 14, 1024  0           ['add_11[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 7, 7, 512)    524800      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 7, 7, 512)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 7, 7, 512)    2359808     ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 7, 7, 512)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 7, 7, 2048)   1050624     ['activation_38[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 7, 7, 2048)   2099200     ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 7, 7, 2048)  8192        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 7, 7, 2048)  8192        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 7, 7, 2048)   0           ['batch_normalization_42[0][0]', \n",
            "                                                                  'batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 7, 7, 2048)   0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 7, 7, 512)    1049088     ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 7, 7, 512)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 7, 7, 512)    2359808     ['activation_40[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 7, 7, 512)    0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 7, 7, 2048)   1050624     ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 7, 7, 2048)  8192        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 7, 7, 2048)   0           ['batch_normalization_46[0][0]', \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 7, 7, 2048)   0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 7, 7, 512)    1049088     ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 7, 7, 512)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 7, 7, 512)    2359808     ['activation_43[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 7, 7, 512)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 7, 7, 2048)   1050624     ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 7, 7, 2048)  8192        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 7, 7, 2048)   0           ['batch_normalization_49[0][0]', \n",
            "                                                                  'activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 7, 7, 2048)   0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 3, 3, 2048)  0           ['activation_45[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 18432)        0           ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 4)            73732       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,379,076\n",
            "Trainable params: 23,327,492\n",
            "Non-trainable params: 51,584\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_res().summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7REkjcFGIDqC",
        "outputId": "ae2a6161-614c-4d85-ec1e-36cdffda4637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "182/182 [==============================] - 51s 254ms/step - loss: 2.2443 - accuracy: 0.4020 - val_loss: 1.4084 - val_accuracy: 0.3610\n",
            "Epoch 2/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 1.0077 - accuracy: 0.5821 - val_loss: 2.6722 - val_accuracy: 0.2661\n",
            "Epoch 3/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.8473 - accuracy: 0.6542 - val_loss: 2.0610 - val_accuracy: 0.3956\n",
            "Epoch 4/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.7506 - accuracy: 0.6985 - val_loss: 1.1763 - val_accuracy: 0.5490\n",
            "Epoch 5/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.6988 - accuracy: 0.7219 - val_loss: 1.3136 - val_accuracy: 0.5242\n",
            "Epoch 6/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.5753 - accuracy: 0.7708 - val_loss: 0.6953 - val_accuracy: 0.7082\n",
            "Epoch 7/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.5087 - accuracy: 0.8000 - val_loss: 0.8269 - val_accuracy: 0.6944\n",
            "Epoch 8/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.4258 - accuracy: 0.8347 - val_loss: 1.5288 - val_accuracy: 0.4797\n",
            "Epoch 9/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.3685 - accuracy: 0.8597 - val_loss: 0.8008 - val_accuracy: 0.6775\n",
            "Epoch 10/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.3399 - accuracy: 0.8729 - val_loss: 2.0784 - val_accuracy: 0.4283\n",
            "Epoch 11/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.2827 - accuracy: 0.8906 - val_loss: 1.0417 - val_accuracy: 0.6795\n",
            "Epoch 12/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.2107 - accuracy: 0.9219 - val_loss: 1.2639 - val_accuracy: 0.6825\n",
            "Epoch 13/100\n",
            "182/182 [==============================] - 45s 247ms/step - loss: 0.1646 - accuracy: 0.9395 - val_loss: 1.0568 - val_accuracy: 0.7171\n",
            "Epoch 14/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.1604 - accuracy: 0.9422 - val_loss: 1.5663 - val_accuracy: 0.5143\n",
            "Epoch 15/100\n",
            "182/182 [==============================] - 45s 247ms/step - loss: 0.1464 - accuracy: 0.9465 - val_loss: 1.0688 - val_accuracy: 0.7082\n",
            "Epoch 16/100\n",
            "182/182 [==============================] - 45s 247ms/step - loss: 0.1052 - accuracy: 0.9624 - val_loss: 3.1865 - val_accuracy: 0.5015\n",
            "Epoch 17/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.1018 - accuracy: 0.9638 - val_loss: 1.1198 - val_accuracy: 0.7161\n",
            "Epoch 18/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0952 - accuracy: 0.9677 - val_loss: 1.0996 - val_accuracy: 0.7003\n",
            "Epoch 19/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.1028 - accuracy: 0.9626 - val_loss: 1.0279 - val_accuracy: 0.7319\n",
            "Epoch 20/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0661 - accuracy: 0.9759 - val_loss: 1.3459 - val_accuracy: 0.7112\n",
            "Epoch 21/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0728 - accuracy: 0.9735 - val_loss: 1.0548 - val_accuracy: 0.7557\n",
            "Epoch 22/100\n",
            "182/182 [==============================] - 45s 247ms/step - loss: 0.0777 - accuracy: 0.9714 - val_loss: 1.0747 - val_accuracy: 0.7676\n",
            "Epoch 23/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0740 - accuracy: 0.9749 - val_loss: 1.2987 - val_accuracy: 0.7211\n",
            "Epoch 24/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0772 - accuracy: 0.9736 - val_loss: 1.0407 - val_accuracy: 0.7507\n",
            "Epoch 25/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0538 - accuracy: 0.9822 - val_loss: 1.4312 - val_accuracy: 0.7329\n",
            "Epoch 26/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0645 - accuracy: 0.9771 - val_loss: 1.0463 - val_accuracy: 0.7765\n",
            "Epoch 27/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0516 - accuracy: 0.9820 - val_loss: 1.3854 - val_accuracy: 0.7221\n",
            "Epoch 28/100\n",
            "182/182 [==============================] - 45s 247ms/step - loss: 0.0680 - accuracy: 0.9770 - val_loss: 1.1834 - val_accuracy: 0.7636\n",
            "Epoch 29/100\n",
            "182/182 [==============================] - 45s 247ms/step - loss: 0.0681 - accuracy: 0.9771 - val_loss: 1.6247 - val_accuracy: 0.7201\n",
            "Epoch 30/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0511 - accuracy: 0.9820 - val_loss: 1.0623 - val_accuracy: 0.7587\n",
            "Epoch 31/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0585 - accuracy: 0.9791 - val_loss: 1.1100 - val_accuracy: 0.7685\n",
            "Epoch 32/100\n",
            "182/182 [==============================] - 45s 247ms/step - loss: 0.0411 - accuracy: 0.9853 - val_loss: 2.5794 - val_accuracy: 0.6063\n",
            "Epoch 33/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0429 - accuracy: 0.9849 - val_loss: 1.9171 - val_accuracy: 0.6855\n",
            "Epoch 34/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0720 - accuracy: 0.9735 - val_loss: 1.4262 - val_accuracy: 0.7399\n",
            "Epoch 35/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0348 - accuracy: 0.9879 - val_loss: 1.2542 - val_accuracy: 0.7557\n",
            "Epoch 36/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0248 - accuracy: 0.9913 - val_loss: 1.7305 - val_accuracy: 0.7329\n",
            "Epoch 37/100\n",
            "182/182 [==============================] - 45s 247ms/step - loss: 0.0464 - accuracy: 0.9835 - val_loss: 1.5463 - val_accuracy: 0.7319\n",
            "Epoch 38/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0632 - accuracy: 0.9764 - val_loss: 1.3808 - val_accuracy: 0.7458\n",
            "Epoch 39/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0515 - accuracy: 0.9823 - val_loss: 2.5368 - val_accuracy: 0.6518\n",
            "Epoch 40/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0470 - accuracy: 0.9846 - val_loss: 1.4402 - val_accuracy: 0.7725\n",
            "Epoch 41/100\n",
            "182/182 [==============================] - 45s 247ms/step - loss: 0.0413 - accuracy: 0.9854 - val_loss: 1.8190 - val_accuracy: 0.7240\n",
            "Epoch 42/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0364 - accuracy: 0.9876 - val_loss: 2.1208 - val_accuracy: 0.6301\n",
            "Epoch 43/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0462 - accuracy: 0.9844 - val_loss: 2.8109 - val_accuracy: 0.5846\n",
            "Epoch 44/100\n",
            "182/182 [==============================] - 45s 247ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 1.5884 - val_accuracy: 0.7893\n",
            "Epoch 45/100\n",
            "182/182 [==============================] - 45s 247ms/step - loss: 0.0320 - accuracy: 0.9904 - val_loss: 1.4062 - val_accuracy: 0.7873\n",
            "Epoch 46/100\n",
            "182/182 [==============================] - 45s 247ms/step - loss: 0.0281 - accuracy: 0.9900 - val_loss: 1.9031 - val_accuracy: 0.6775\n",
            "Epoch 47/100\n",
            "182/182 [==============================] - 45s 247ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 1.8346 - val_accuracy: 0.7319\n",
            "Epoch 48/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0510 - accuracy: 0.9831 - val_loss: 1.2443 - val_accuracy: 0.7656\n",
            "Epoch 49/100\n",
            "182/182 [==============================] - 45s 247ms/step - loss: 0.0462 - accuracy: 0.9846 - val_loss: 1.3587 - val_accuracy: 0.7705\n",
            "Epoch 50/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0218 - accuracy: 0.9921 - val_loss: 1.8896 - val_accuracy: 0.7626\n",
            "Epoch 51/100\n",
            "182/182 [==============================] - 45s 247ms/step - loss: 0.0566 - accuracy: 0.9806 - val_loss: 1.4455 - val_accuracy: 0.7587\n",
            "Epoch 52/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 1.3745 - val_accuracy: 0.7844\n",
            "Epoch 53/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0167 - accuracy: 0.9936 - val_loss: 1.4308 - val_accuracy: 0.8002\n",
            "Epoch 54/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0249 - accuracy: 0.9914 - val_loss: 1.5476 - val_accuracy: 0.7646\n",
            "Epoch 55/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0433 - accuracy: 0.9864 - val_loss: 1.5880 - val_accuracy: 0.7834\n",
            "Epoch 56/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0323 - accuracy: 0.9881 - val_loss: 2.7335 - val_accuracy: 0.6182\n",
            "Epoch 57/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0359 - accuracy: 0.9893 - val_loss: 2.0713 - val_accuracy: 0.6271\n",
            "Epoch 58/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 1.5918 - val_accuracy: 0.7913\n",
            "Epoch 59/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 1.3270 - val_accuracy: 0.8140\n",
            "Epoch 60/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 1.4710 - val_accuracy: 0.7982\n",
            "Epoch 61/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 1.3892 - val_accuracy: 0.8042\n",
            "Epoch 62/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 3.0380e-04 - accuracy: 1.0000 - val_loss: 1.3054 - val_accuracy: 0.8150\n",
            "Epoch 63/100\n",
            "182/182 [==============================] - 45s 247ms/step - loss: 1.3338e-04 - accuracy: 1.0000 - val_loss: 1.3241 - val_accuracy: 0.8190\n",
            "Epoch 64/100\n",
            "182/182 [==============================] - 45s 248ms/step - loss: 7.1713e-05 - accuracy: 1.0000 - val_loss: 1.3332 - val_accuracy: 0.8229\n",
            "Epoch 65/100\n",
            "182/182 [==============================] - 45s 247ms/step - loss: 5.2485e-05 - accuracy: 1.0000 - val_loss: 1.3492 - val_accuracy: 0.8220\n",
            "Epoch 66/100\n",
            " 88/182 [=============>................] - ETA: 22s - loss: 2.1201e-05 - accuracy: 1.0000"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-6ecd74949105>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = model_res()\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=50, validation_data = (X_test,y_test), epochs = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "fhn5runSvbm4",
        "outputId": "b5ebbe9a-f783-4c0a-ebda-75cb7bab19cb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['loss', 'val_loss', \"accuracy\", 'val_accuracy'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "4_categorical_inception_bn.ipynb의 사본",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
